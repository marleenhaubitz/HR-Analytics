{\rtf1\ansi\ansicpg1252\cocoartf2758
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww30040\viewh18340\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Week 4

Experimentign and diving into the ROC Curve: 
The ROC curve is a graphical representation of the performance of a binary classification model across different classification thresholds.
It plots the True Positive Rate (Sensitivity) against the False Positive Rate (1 - Specificity) for various threshold values.
The diagonal line represents random chance, and the goal is for the ROC curve to be as far away from this line as possible. (Except being below, then it would be worse than chance)

AUC quantifies the overall performance of a classification model. It represents the area under the ROC curve.
AUC values range from 0 to 1. A model with perfect discrimination has an AUC of 1, while a model with that is similar to random chance has an AUC of 0.5.

}
